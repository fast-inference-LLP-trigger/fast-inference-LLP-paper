{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aY_PaXoLCRss"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "def make_binary(dataset):\n",
        "    data = dataset.flatten()\n",
        "    data_binary = [1 if i > 0 else 0 for i in data]\n",
        "    data_binary = np.reshape(data_binary, (dataset.shape[0], dataset.shape[1], dataset.shape[2]))\n",
        "    print(data_binary.shape)\n",
        "    return data_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5afasVMcCRsu",
        "outputId": "b9efcb50-9c8d-4164-bc4a-850e3afd4dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(90000, 20, 333)\n",
            "(2700, 20, 333)\n",
            "(2700, 20, 333)\n",
            "(90000, 20, 333, 1) (2700, 20, 333, 1) (2700, 20, 333, 1)\n"
          ]
        }
      ],
      "source": [
        "t2 = np.load('MS_bkg_2_mod.npz')\n",
        "t3 = np.load('MS_bkg_3_mod.npz')\n",
        "t4 = np.load('MS_bkg_4_mod.npz')\n",
        "\n",
        "\n",
        "a2 = np.load('MS_sgn_2_mod.npz')\n",
        "a3 = np.load('MS_sgn_3_mod.npz')\n",
        "a4 = np.load('MS_sgn_4_mod.npz')\n",
        "a5 = np.load('MS_sgn_5_mod.npz')\n",
        "a6 = np.load('MS_sgn_6_mod.npz')\n",
        "a7 = np.load('MS_sgn_7_mod.npz')\n",
        "a8 = np.load('MS_sgn_8_mod.npz')\n",
        "a9 = np.load('MS_sgn_9_mod.npz')\n",
        "a10 = np.load('MS_sgn_10_mod.npz')\n",
        "\n",
        "data2=np.asarray(t2['data_noise'])\n",
        "dataa2=np.asarray(a2['data_noise'])\n",
        "data3 = np.asarray(t3['data_noise'])\n",
        "dataa3=np.asarray(a3['data_noise'])\n",
        "data4 = np.asarray(t4['data_noise'])\n",
        "dataa4=np.asarray(a4['data_noise'])\n",
        "dataa5=np.asarray(a5['data_noise'])\n",
        "dataa6=np.asarray(a6['data_noise'])\n",
        "dataa7=np.asarray(a7['data_noise'])\n",
        "dataa8=np.asarray(a8['data_noise'])\n",
        "dataa9=np.asarray(a9['data_noise'])\n",
        "dataa10=np.asarray(a10['data_noise'])\n",
        "\n",
        "datat=np.concatenate((data2[0:30000],data3[0:30000],data4[0:30000]))\n",
        "dataN=np.concatenate((data2[0:900],data3[0:900],data4[0:900]))\n",
        "dataA=np.concatenate((dataa2[0:300],dataa3[0:300],dataa4[0:300],dataa5[0:300],dataa6[0:300],dataa7[0:300],dataa8[0:300],dataa9[0:300],dataa10[0:300]))\n",
        "datat=make_binary(datat)\n",
        "dataA=make_binary(dataA)\n",
        "dataN=make_binary(dataN)\n",
        "datat=np.reshape(datat,(90000,20,333,1))\n",
        "dataA=np.reshape(dataA,(2700,20,333,1))\n",
        "dataN=np.reshape(dataN,(2700,20,333,1))\n",
        "print(datat.shape,dataN.shape,dataA.shape)\n",
        "np.savez('dataN',data=dataN)\n",
        "np.savez('datat',data=datat)\n",
        "np.savez('dataA',data=dataA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxrWZm-4Nt-2",
        "outputId": "7cf58a81-cf92-441b-b217-91a1caa52022",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 20, 333, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 10, 164, 128)      1664      \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 5, 80, 64)         98368     \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 4, 38, 48)         36912     \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 3, 17, 32)         18464     \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 2, 6, 16)          6160      \n",
            "_________________________________________________________________\n",
            "flatten1 (Flatten)           (None, 192)               0         \n",
            "_________________________________________________________________\n",
            "dense0 (Dense)               (None, 5)                 965       \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 192)               1152      \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 2, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv_transpose2 (Conv2DTrans (None, 3, 16, 32)         6176      \n",
            "_________________________________________________________________\n",
            "conv_transpose3 (Conv2DTrans (None, 4, 36, 48)         18480     \n",
            "_________________________________________________________________\n",
            "conv_transpose4 (Conv2DTrans (None, 5, 77, 64)         43072     \n",
            "_________________________________________________________________\n",
            "conv_transpose5 (Conv2DTrans (None, 10, 162, 128)      163968    \n",
            "_________________________________________________________________\n",
            "conv_transpose6 (Conv2DTrans (None, 20, 333, 1)        2817      \n",
            "=================================================================\n",
            "Total params: 398,198\n",
            "Trainable params: 398,198\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-28 09:52:03.490746: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2023-04-28 09:52:03.520393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
            "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
            "2023-04-28 09:52:03.520493: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-04-28 09:52:03.520576: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-04-28 09:52:03.564925: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2023-04-28 09:52:03.565265: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2023-04-28 09:52:03.565362: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-04-28 09:52:03.565430: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-04-28 09:52:03.565495: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-04-28 09:52:03.565508: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-04-28 09:52:03.566047: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 09:52:03.579991: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz\n",
            "2023-04-28 09:52:03.593467: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50f95c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-04-28 09:52:03.593490: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-04-28 09:52:03.595015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2023-04-28 09:52:03.595032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
          ]
        }
      ],
      "source": [
        "# AE simple model\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "input = tf.keras.layers.Input(shape=(20, 333, 1),name='input')\n",
        "x = tf.keras.layers.Conv2D(128, (2,6), activation='relu', strides=(2,2), name='conv2')(input)\n",
        "x = tf.keras.layers.Conv2D(64, (2,6), activation='relu', strides=(2,2), name='conv3')(x)\n",
        "x = tf.keras.layers.Conv2D(48, (2,6), activation='relu', strides=(1,2), name='conv4')(x)\n",
        "x = tf.keras.layers.Conv2D(32, (2,6), activation='relu', strides=(1,2),name='conv5')(x)\n",
        "x = tf.keras.layers.Conv2D(16, (2,6), activation='relu', strides=(1,2),name='conv6')(x)\n",
        "x = tf.keras.layers.Flatten(name='flatten1')(x)\n",
        "x = tf.keras.layers.Dense(5,name=\"dense0\")(x)\n",
        "x = tf.keras.layers.Dense(2*6*16,name=\"dense1\",activation='relu')(x)\n",
        "x = tf.keras.layers.Reshape((2,6,16),name='reshape')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(32, (2,6), activation='relu', strides=(1,2),name='conv_transpose2')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(48, (2,6), activation='relu', strides=(1,2), name='conv_transpose3')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(64, (2,7), activation='relu', strides=(1,2), name='conv_transpose4')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(128, (2,10), activation='relu', strides=(2,2), name='conv_transpose5')(x)\n",
        "output = tf.keras.layers.Conv2DTranspose(1, (2,11), activation='relu', strides=(2,2), name='conv_transpose6')(x)\n",
        "\n",
        "bce=tf.keras.losses.BinaryCrossentropy()\n",
        "autoencoder_preTrain = Model(input, output, name=\"AE\")\n",
        "optimizer = Adam()\n",
        "autoencoder_preTrain.compile(optimizer=optimizer, loss=bce)\n",
        "autoencoder_preTrain.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI491H15A--d",
        "outputId": "214dffda-8b68-477f-9393-d0f66955d1d9",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-28 09:52:03.735076: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3836160000 exceeds 10% of free system memory.\n",
            "2023-04-28 09:52:06.291687: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3836160000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1233\n",
            "Epoch 00001: val_loss improved from inf to 0.15992, saving model to AEpreTrain.h5\n",
            "563/563 [==============================] - 285s 507ms/step - loss: 0.1233 - val_loss: 0.1599\n",
            "Epoch 2/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1189\n",
            "Epoch 00002: val_loss improved from 0.15992 to 0.15923, saving model to AEpreTrain.h5\n",
            "563/563 [==============================] - 278s 494ms/step - loss: 0.1189 - val_loss: 0.1592\n",
            "Epoch 3/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1192\n",
            "Epoch 00003: val_loss did not improve from 0.15923\n",
            "563/563 [==============================] - 270s 479ms/step - loss: 0.1192 - val_loss: 0.1593\n",
            "Epoch 4/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1180\n",
            "Epoch 00004: val_loss improved from 0.15923 to 0.15888, saving model to AEpreTrain.h5\n",
            "563/563 [==============================] - 260s 462ms/step - loss: 0.1180 - val_loss: 0.1589\n",
            "Epoch 5/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1174\n",
            "Epoch 00005: val_loss improved from 0.15888 to 0.15830, saving model to AEpreTrain.h5\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.1174 - val_loss: 0.1583\n",
            "Epoch 6/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1170\n",
            "Epoch 00006: val_loss did not improve from 0.15830\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.1170 - val_loss: 0.1606\n",
            "Epoch 7/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1163\n",
            "Epoch 00007: val_loss improved from 0.15830 to 0.15755, saving model to AEpreTrain.h5\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.1163 - val_loss: 0.1576\n",
            "Epoch 8/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1196\n",
            "Epoch 00008: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 262s 466ms/step - loss: 0.1196 - val_loss: 0.1591\n",
            "Epoch 9/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1184\n",
            "Epoch 00009: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 261s 463ms/step - loss: 0.1184 - val_loss: 0.1594\n",
            "Epoch 10/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1174\n",
            "Epoch 00010: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 261s 463ms/step - loss: 0.1174 - val_loss: 0.1585\n",
            "Epoch 11/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1168\n",
            "Epoch 00011: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 260s 462ms/step - loss: 0.1168 - val_loss: 0.1585\n",
            "Epoch 12/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1183\n",
            "Epoch 00012: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 263s 467ms/step - loss: 0.1183 - val_loss: 0.1585\n",
            "Epoch 13/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1185\n",
            "Epoch 00013: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 263s 466ms/step - loss: 0.1185 - val_loss: 0.1593\n",
            "Epoch 14/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1193\n",
            "Epoch 00014: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.1193 - val_loss: 0.1595\n",
            "Epoch 15/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1183\n",
            "Epoch 00015: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 260s 462ms/step - loss: 0.1183 - val_loss: 0.1589\n",
            "Epoch 16/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1177\n",
            "Epoch 00016: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.1177 - val_loss: 0.1590\n",
            "Epoch 17/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1187\n",
            "Epoch 00017: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 263s 468ms/step - loss: 0.1187 - val_loss: 0.1594\n",
            "Epoch 18/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1175\n",
            "Epoch 00018: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.1175 - val_loss: 0.1588\n",
            "Epoch 19/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1170\n",
            "Epoch 00019: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 260s 462ms/step - loss: 0.1170 - val_loss: 0.1586\n",
            "Epoch 20/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1176\n",
            "Epoch 00020: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 263s 467ms/step - loss: 0.1176 - val_loss: 0.1586\n",
            "Epoch 21/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1177\n",
            "Epoch 00021: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.1177 - val_loss: 0.1590\n",
            "Epoch 22/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1178\n",
            "Epoch 00022: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 260s 463ms/step - loss: 0.1178 - val_loss: 0.1589\n",
            "Epoch 23/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1167\n",
            "Epoch 00023: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 263s 468ms/step - loss: 0.1167 - val_loss: 0.1584\n",
            "Epoch 24/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1177\n",
            "Epoch 00024: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 264s 469ms/step - loss: 0.1177 - val_loss: 0.1589\n",
            "Epoch 25/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1168\n",
            "Epoch 00025: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 262s 466ms/step - loss: 0.1168 - val_loss: 0.1581\n",
            "Epoch 26/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1169\n",
            "Epoch 00026: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 264s 469ms/step - loss: 0.1169 - val_loss: 0.1589\n",
            "Epoch 27/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1165\n",
            "Epoch 00027: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.1165 - val_loss: 0.1582\n",
            "Epoch 28/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1161\n",
            "Epoch 00028: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.1161 - val_loss: 0.1587\n",
            "Epoch 29/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1157\n",
            "Epoch 00029: val_loss did not improve from 0.15755\n",
            "563/563 [==============================] - 259s 461ms/step - loss: 0.1157 - val_loss: 0.1577\n",
            "Epoch 30/30\n",
            "563/563 [==============================] - ETA: 0s - loss: 0.1154\n",
            "Epoch 00030: val_loss improved from 0.15755 to 0.15711, saving model to AEpreTrain.h5\n",
            "563/563 [==============================] - 262s 466ms/step - loss: 0.1154 - val_loss: 0.1571\n"
          ]
        }
      ],
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='AEpreTrain.h5',\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,                   \n",
        "                             mode='min')\n",
        "callbacks = [checkpoint]\n",
        "history=autoencoder_preTrain.fit(x=datat,y=datat,epochs=30,batch_size=128,validation_split=.2, verbose=1,callbacks=callbacks,shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xD1RiyNZCRsx"
      },
      "outputs": [],
      "source": [
        "selected_pm_layers = ['flatten1','dense0','dense1']\n",
        "selected_pm_layer_weights = [1.0,1.0, 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxMCvG8cCRsx"
      },
      "outputs": [],
      "source": [
        "autoencoder_preTrain=tf.keras.models.load_model('AEpreTrain.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxZkYpsHCRsx"
      },
      "outputs": [],
      "source": [
        "autoencoder.set_weights(autoencoder_preTrain.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXfDzsguCRsx",
        "outputId": "17c849da-361c-4978-e6b9-b6da6dab9f5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor 'flatten1/Reshape_3:0' shape=(None, 192) dtype=float32>,\n",
              " <tf.Tensor 'dense0/BiasAdd_3:0' shape=(None, 5) dtype=float32>,\n",
              " <tf.Tensor 'dense1/Relu_3:0' shape=(None, 192) dtype=float32>]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs = [autoencoder_preTrain.get_layer(l).output for l in selected_pm_layers]\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R17Te3V9CRsy"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_pre = Model(autoencoder_preTrain.input, outputs)\n",
        "\n",
        "\n",
        "def perceptual_loss(x, decoted):\n",
        "    '''Perceptual loss for the DFC VAE'''\n",
        "\n",
        "\n",
        "    #this takes the hidden rep of the input image and the decodated one\n",
        "    h1_list = model_pre(x)\n",
        "    h2_list = model_pre(decoted)\n",
        "    rc_loss = 0.\n",
        "\n",
        "    for h1, h2, weight in zip(h1_list, h2_list, selected_pm_layer_weights):\n",
        "        h1 = tf.keras.backend.batch_flatten(h1)\n",
        "        h2 = tf.keras.backend.batch_flatten(h2)\n",
        "        rc_loss = rc_loss + weight * tf.keras.backend.sum(tf.keras.backend.square(h1 - h2), axis=-1)\n",
        "    \n",
        "    return rc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktUiOgYZCRsz",
        "outputId": "ed688524-f724-49a8-b02f-04c73ab6dcaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"AEperceptual\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 20, 333, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 10, 164, 128)      1664      \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 5, 80, 64)         98368     \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 4, 38, 48)         36912     \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 3, 17, 32)         18464     \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 2, 6, 16)          6160      \n",
            "_________________________________________________________________\n",
            "flatten1 (Flatten)           (None, 192)               0         \n",
            "_________________________________________________________________\n",
            "dense0 (Dense)               (None, 5)                 965       \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 192)               1152      \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 2, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv_transpose2 (Conv2DTrans (None, 3, 16, 32)         6176      \n",
            "_________________________________________________________________\n",
            "conv_transpose3 (Conv2DTrans (None, 4, 36, 48)         18480     \n",
            "_________________________________________________________________\n",
            "conv_transpose4 (Conv2DTrans (None, 5, 77, 64)         43072     \n",
            "_________________________________________________________________\n",
            "conv_transpose5 (Conv2DTrans (None, 10, 162, 128)      163968    \n",
            "_________________________________________________________________\n",
            "conv_transpose6 (Conv2DTrans (None, 20, 333, 1)        2817      \n",
            "=================================================================\n",
            "Total params: 398,198\n",
            "Trainable params: 398,198\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = tf.keras.layers.Input(shape=(20, 333, 1),name='input')\n",
        "x = tf.keras.layers.Conv2D(128, (2,6), activation='relu', strides=(2,2), name='conv2')(input)\n",
        "x = tf.keras.layers.Conv2D(64, (2,6), activation='relu', strides=(2,2), name='conv3')(x)\n",
        "x = tf.keras.layers.Conv2D(48, (2,6), activation='relu', strides=(1,2), name='conv4')(x)\n",
        "x = tf.keras.layers.Conv2D(32, (2,6), activation='relu', strides=(1,2),name='conv5')(x)\n",
        "x = tf.keras.layers.Conv2D(16, (2,6), activation='relu', strides=(1,2),name='conv6')(x)\n",
        "x = tf.keras.layers.Flatten(name='flatten1')(x)\n",
        "x = tf.keras.layers.Dense(5,name=\"dense0\")(x)\n",
        "x = tf.keras.layers.Dense(2*6*16,name=\"dense1\",activation='relu')(x)\n",
        "x = tf.keras.layers.Reshape((2,6,16),name='reshape')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(32, (2,6), activation='relu', strides=(1,2),name='conv_transpose2')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(48, (2,6), activation='relu', strides=(1,2), name='conv_transpose3')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(64, (2,7), activation='relu', strides=(1,2), name='conv_transpose4')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(128, (2,10), activation='relu', strides=(2,2), name='conv_transpose5')(x)\n",
        "output = tf.keras.layers.Conv2DTranspose(1, (2,11), activation='relu', strides=(2,2), name='conv_transpose6')(x)\n",
        "\n",
        "optimizer = Adam()\n",
        "autoencoder=Model(input,output,name=\"AEperceptual\")\n",
        "autoencoder.compile(optimizer=optimizer, loss=perceptual_loss)\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "EndvM3yDCRs0",
        "outputId": "b5903b41-b349-4938-83e2-a0a163d9885e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-28 12:09:15.373538: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3836160000 exceeds 10% of free system memory.\n",
            "2023-04-28 12:09:18.030542: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3836160000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 22.1494\n",
            "Epoch 00001: val_loss improved from inf to 11.72815, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 363s 323ms/step - loss: 22.1494 - val_loss: 11.7281\n",
            "Epoch 2/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 4.9302\n",
            "Epoch 00002: val_loss improved from 11.72815 to 7.24018, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 366s 326ms/step - loss: 4.9302 - val_loss: 7.2402\n",
            "Epoch 3/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 3.6450\n",
            "Epoch 00003: val_loss improved from 7.24018 to 5.93735, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 367s 326ms/step - loss: 3.6450 - val_loss: 5.9374\n",
            "Epoch 4/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 3.1082\n",
            "Epoch 00004: val_loss improved from 5.93735 to 5.28876, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 362s 322ms/step - loss: 3.1082 - val_loss: 5.2888\n",
            "Epoch 5/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 2.7512\n",
            "Epoch 00005: val_loss did not improve from 5.28876\n",
            "1125/1125 [==============================] - 359s 319ms/step - loss: 2.7512 - val_loss: 5.8811\n",
            "Epoch 6/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 2.5637\n",
            "Epoch 00006: val_loss improved from 5.28876 to 4.88647, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 359s 319ms/step - loss: 2.5637 - val_loss: 4.8865\n",
            "Epoch 7/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 2.4038\n",
            "Epoch 00007: val_loss did not improve from 4.88647\n",
            "1125/1125 [==============================] - 362s 322ms/step - loss: 2.4038 - val_loss: 5.3123\n",
            "Epoch 8/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 2.2853\n",
            "Epoch 00008: val_loss did not improve from 4.88647\n",
            "1125/1125 [==============================] - 365s 324ms/step - loss: 2.2853 - val_loss: 5.3077\n",
            "Epoch 9/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 2.2112\n",
            "Epoch 00009: val_loss improved from 4.88647 to 4.51025, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 362s 322ms/step - loss: 2.2112 - val_loss: 4.5102\n",
            "Epoch 10/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 2.0869\n",
            "Epoch 00010: val_loss improved from 4.51025 to 4.50956, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 358s 318ms/step - loss: 2.0869 - val_loss: 4.5096\n",
            "Epoch 11/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 2.0515\n",
            "Epoch 00011: val_loss improved from 4.50956 to 4.29406, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 366s 325ms/step - loss: 2.0515 - val_loss: 4.2941\n",
            "Epoch 12/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.9842\n",
            "Epoch 00012: val_loss improved from 4.29406 to 4.29367, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 363s 323ms/step - loss: 1.9842 - val_loss: 4.2937\n",
            "Epoch 13/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.9231\n",
            "Epoch 00013: val_loss did not improve from 4.29367\n",
            "1125/1125 [==============================] - 363s 323ms/step - loss: 1.9231 - val_loss: 4.6749\n",
            "Epoch 14/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.8820\n",
            "Epoch 00014: val_loss improved from 4.29367 to 4.27453, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 355s 315ms/step - loss: 1.8820 - val_loss: 4.2745\n",
            "Epoch 15/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.8554\n",
            "Epoch 00015: val_loss improved from 4.27453 to 3.98887, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 362s 322ms/step - loss: 1.8554 - val_loss: 3.9889\n",
            "Epoch 16/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.7972\n",
            "Epoch 00016: val_loss did not improve from 3.98887\n",
            "1125/1125 [==============================] - 359s 319ms/step - loss: 1.7972 - val_loss: 4.1783\n",
            "Epoch 17/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.7979\n",
            "Epoch 00017: val_loss did not improve from 3.98887\n",
            "1125/1125 [==============================] - 362s 322ms/step - loss: 1.7979 - val_loss: 4.0020\n",
            "Epoch 18/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.7522\n",
            "Epoch 00018: val_loss did not improve from 3.98887\n",
            "1125/1125 [==============================] - 366s 326ms/step - loss: 1.7522 - val_loss: 4.3367\n",
            "Epoch 19/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.7300\n",
            "Epoch 00019: val_loss did not improve from 3.98887\n",
            "1125/1125 [==============================] - 365s 324ms/step - loss: 1.7300 - val_loss: 4.0785\n",
            "Epoch 20/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.7174\n",
            "Epoch 00020: val_loss improved from 3.98887 to 3.93046, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 375s 333ms/step - loss: 1.7174 - val_loss: 3.9305\n",
            "Epoch 21/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.6614\n",
            "Epoch 00021: val_loss did not improve from 3.93046\n",
            "1125/1125 [==============================] - 361s 321ms/step - loss: 1.6614 - val_loss: 3.9389\n",
            "Epoch 22/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.6509\n",
            "Epoch 00022: val_loss improved from 3.93046 to 3.92052, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 364s 324ms/step - loss: 1.6509 - val_loss: 3.9205\n",
            "Epoch 23/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.6264\n",
            "Epoch 00023: val_loss improved from 3.92052 to 3.90784, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 369s 328ms/step - loss: 1.6264 - val_loss: 3.9078\n",
            "Epoch 24/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.6224\n",
            "Epoch 00024: val_loss did not improve from 3.90784\n",
            "1125/1125 [==============================] - 369s 328ms/step - loss: 1.6224 - val_loss: 3.9768\n",
            "Epoch 25/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.5948\n",
            "Epoch 00025: val_loss did not improve from 3.90784\n",
            "1125/1125 [==============================] - 377s 335ms/step - loss: 1.5948 - val_loss: 3.9122\n",
            "Epoch 26/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.5848\n",
            "Epoch 00026: val_loss improved from 3.90784 to 3.80651, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 379s 337ms/step - loss: 1.5848 - val_loss: 3.8065\n",
            "Epoch 27/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.5646\n",
            "Epoch 00027: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 374s 333ms/step - loss: 1.5646 - val_loss: 3.9161\n",
            "Epoch 28/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.5596\n",
            "Epoch 00028: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 376s 335ms/step - loss: 1.5596 - val_loss: 4.1101\n",
            "Epoch 29/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.5397\n",
            "Epoch 00029: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 375s 333ms/step - loss: 1.5397 - val_loss: 3.8910\n",
            "Epoch 30/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.5338\n",
            "Epoch 00030: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 374s 332ms/step - loss: 1.5338 - val_loss: 4.0618\n",
            "Epoch 31/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.5120\n",
            "Epoch 00031: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 377s 335ms/step - loss: 1.5120 - val_loss: 4.1416\n",
            "Epoch 32/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.5034\n",
            "Epoch 00032: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 371s 329ms/step - loss: 1.5034 - val_loss: 3.8305\n",
            "Epoch 33/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4843\n",
            "Epoch 00033: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 382s 340ms/step - loss: 1.4843 - val_loss: 3.8313\n",
            "Epoch 34/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4759\n",
            "Epoch 00034: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 374s 332ms/step - loss: 1.4759 - val_loss: 4.1747\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4860\n",
            "Epoch 00035: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 373s 332ms/step - loss: 1.4860 - val_loss: 3.8399\n",
            "Epoch 36/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4568\n",
            "Epoch 00036: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 371s 330ms/step - loss: 1.4568 - val_loss: 4.0500\n",
            "Epoch 37/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4451\n",
            "Epoch 00037: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 373s 332ms/step - loss: 1.4451 - val_loss: 3.9718\n",
            "Epoch 38/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4549\n",
            "Epoch 00038: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 370s 329ms/step - loss: 1.4549 - val_loss: 3.8754\n",
            "Epoch 39/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4355\n",
            "Epoch 00039: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 371s 329ms/step - loss: 1.4355 - val_loss: 3.8706\n",
            "Epoch 40/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4294\n",
            "Epoch 00040: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 367s 326ms/step - loss: 1.4294 - val_loss: 3.8726\n",
            "Epoch 41/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4149\n",
            "Epoch 00041: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 368s 327ms/step - loss: 1.4149 - val_loss: 3.8703\n",
            "Epoch 42/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4271\n",
            "Epoch 00042: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 360s 320ms/step - loss: 1.4271 - val_loss: 3.8139\n",
            "Epoch 43/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3969\n",
            "Epoch 00043: val_loss did not improve from 3.80651\n",
            "1125/1125 [==============================] - 358s 319ms/step - loss: 1.3969 - val_loss: 3.9686\n",
            "Epoch 44/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.4021\n",
            "Epoch 00044: val_loss improved from 3.80651 to 3.79550, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 358s 318ms/step - loss: 1.4021 - val_loss: 3.7955\n",
            "Epoch 45/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3823\n",
            "Epoch 00045: val_loss improved from 3.79550 to 3.78658, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 368s 327ms/step - loss: 1.3823 - val_loss: 3.7866\n",
            "Epoch 46/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3889\n",
            "Epoch 00046: val_loss did not improve from 3.78658\n",
            "1125/1125 [==============================] - 365s 325ms/step - loss: 1.3889 - val_loss: 3.9067\n",
            "Epoch 47/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3807\n",
            "Epoch 00047: val_loss did not improve from 3.78658\n",
            "1125/1125 [==============================] - 360s 320ms/step - loss: 1.3807 - val_loss: 3.8621\n",
            "Epoch 48/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3684\n",
            "Epoch 00048: val_loss did not improve from 3.78658\n",
            "1125/1125 [==============================] - 360s 320ms/step - loss: 1.3684 - val_loss: 4.3866\n",
            "Epoch 49/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3742\n",
            "Epoch 00049: val_loss did not improve from 3.78658\n",
            "1125/1125 [==============================] - 367s 326ms/step - loss: 1.3742 - val_loss: 4.0026\n",
            "Epoch 50/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3554\n",
            "Epoch 00050: val_loss did not improve from 3.78658\n",
            "1125/1125 [==============================] - 364s 324ms/step - loss: 1.3554 - val_loss: 4.0070\n",
            "Epoch 51/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3642\n",
            "Epoch 00051: val_loss did not improve from 3.78658\n",
            "1125/1125 [==============================] - 361s 321ms/step - loss: 1.3642 - val_loss: 3.9462\n",
            "Epoch 52/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3514\n",
            "Epoch 00052: val_loss improved from 3.78658 to 3.76494, saving model to AEperceptual.h5\n",
            "1125/1125 [==============================] - 361s 321ms/step - loss: 1.3514 - val_loss: 3.7649\n",
            "Epoch 53/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3521\n",
            "Epoch 00053: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 361s 321ms/step - loss: 1.3521 - val_loss: 3.9794\n",
            "Epoch 54/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3394\n",
            "Epoch 00054: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 364s 323ms/step - loss: 1.3394 - val_loss: 3.9603\n",
            "Epoch 55/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3217\n",
            "Epoch 00055: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 360s 320ms/step - loss: 1.3217 - val_loss: 3.9969\n",
            "Epoch 56/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3480\n",
            "Epoch 00056: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 359s 319ms/step - loss: 1.3480 - val_loss: 3.9414\n",
            "Epoch 57/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3181\n",
            "Epoch 00057: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 362s 322ms/step - loss: 1.3181 - val_loss: 3.7960\n",
            "Epoch 58/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3108\n",
            "Epoch 00058: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 363s 322ms/step - loss: 1.3108 - val_loss: 3.8578\n",
            "Epoch 59/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3311\n",
            "Epoch 00059: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 364s 324ms/step - loss: 1.3311 - val_loss: 3.8673\n",
            "Epoch 60/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3056\n",
            "Epoch 00060: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 354s 315ms/step - loss: 1.3056 - val_loss: 3.9971\n",
            "Epoch 61/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3048\n",
            "Epoch 00061: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 362s 321ms/step - loss: 1.3048 - val_loss: 3.8426\n",
            "Epoch 62/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3158\n",
            "Epoch 00062: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 368s 327ms/step - loss: 1.3158 - val_loss: 4.1063\n",
            "Epoch 63/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.3060\n",
            "Epoch 00063: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 369s 328ms/step - loss: 1.3060 - val_loss: 3.8979\n",
            "Epoch 64/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2941\n",
            "Epoch 00064: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 358s 318ms/step - loss: 1.2941 - val_loss: 4.1228\n",
            "Epoch 65/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2908\n",
            "Epoch 00065: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 363s 323ms/step - loss: 1.2908 - val_loss: 3.9602\n",
            "Epoch 66/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2971\n",
            "Epoch 00066: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 353s 314ms/step - loss: 1.2971 - val_loss: 3.8590\n",
            "Epoch 67/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2828\n",
            "Epoch 00067: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 355s 316ms/step - loss: 1.2828 - val_loss: 4.0288\n",
            "Epoch 68/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2838\n",
            "Epoch 00068: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 358s 318ms/step - loss: 1.2838 - val_loss: 3.9168\n",
            "Epoch 69/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2843\n",
            "Epoch 00069: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 362s 321ms/step - loss: 1.2843 - val_loss: 3.9729\n",
            "Epoch 70/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2752\n",
            "Epoch 00070: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 359s 319ms/step - loss: 1.2752 - val_loss: 3.8901\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 71/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2801\n",
            "Epoch 00071: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 355s 316ms/step - loss: 1.2801 - val_loss: 3.8685\n",
            "Epoch 72/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2767\n",
            "Epoch 00072: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 363s 323ms/step - loss: 1.2767 - val_loss: 3.8308\n",
            "Epoch 73/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2620\n",
            "Epoch 00073: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 361s 321ms/step - loss: 1.2620 - val_loss: 3.8943\n",
            "Epoch 74/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2668\n",
            "Epoch 00074: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 358s 318ms/step - loss: 1.2668 - val_loss: 3.8623\n",
            "Epoch 75/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2742\n",
            "Epoch 00075: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 361s 321ms/step - loss: 1.2742 - val_loss: 4.0403\n",
            "Epoch 76/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2497\n",
            "Epoch 00076: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 358s 318ms/step - loss: 1.2497 - val_loss: 3.9348\n",
            "Epoch 77/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2717\n",
            "Epoch 00077: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 356s 316ms/step - loss: 1.2717 - val_loss: 3.8794\n",
            "Epoch 78/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2453\n",
            "Epoch 00078: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 356s 316ms/step - loss: 1.2453 - val_loss: 3.9847\n",
            "Epoch 79/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2585\n",
            "Epoch 00079: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 360s 320ms/step - loss: 1.2585 - val_loss: 3.9197\n",
            "Epoch 80/80\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 1.2600\n",
            "Epoch 00080: val_loss did not improve from 3.76494\n",
            "1125/1125 [==============================] - 365s 325ms/step - loss: 1.2600 - val_loss: 3.9184\n"
          ]
        }
      ],
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='AEperceptual.h5', \n",
        "                             monitor='val_loss',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             mode='min')\n",
        "callbacks = [checkpoint]\n",
        "history=autoencoder.fit(x=datat,y=datat,epochs=80,batch_size=64,validation_split=0.2, verbose=1,callbacks=callbacks,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ERoS2sQyCRs0",
        "outputId": "1e88a016-e668-4277-b0ab-6f47f055acfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"AEperceptual\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 20, 333, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 10, 164, 128)      1664      \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 5, 80, 64)         98368     \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 4, 38, 48)         36912     \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 3, 17, 32)         18464     \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 2, 6, 16)          6160      \n",
            "_________________________________________________________________\n",
            "flatten1 (Flatten)           (None, 192)               0         \n",
            "_________________________________________________________________\n",
            "dense0 (Dense)               (None, 5)                 965       \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 192)               1152      \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 2, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv_transpose2 (Conv2DTrans (None, 3, 16, 32)         6176      \n",
            "_________________________________________________________________\n",
            "conv_transpose3 (Conv2DTrans (None, 4, 36, 48)         18480     \n",
            "_________________________________________________________________\n",
            "conv_transpose4 (Conv2DTrans (None, 5, 77, 64)         43072     \n",
            "_________________________________________________________________\n",
            "conv_transpose5 (Conv2DTrans (None, 10, 162, 128)      163968    \n",
            "_________________________________________________________________\n",
            "conv_transpose6 (Conv2DTrans (None, 20, 333, 1)        2817      \n",
            "=================================================================\n",
            "Total params: 398,198\n",
            "Trainable params: 398,198\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "autoencoder=tf.keras.models.load_model('AEperceptual.h5',compile=False)\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "rLeuExfwCRs0",
        "outputId": "6ef9eaa7-e173-4363-eec9-2e1c74567622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input1 (InputLayer)          [(None, 20, 333, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 10, 164, 128)      1664      \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 5, 80, 64)         98368     \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 4, 38, 48)         36912     \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 3, 17, 32)         18464     \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 2, 6, 16)          6160      \n",
            "_________________________________________________________________\n",
            "flatten1 (Flatten)           (None, 192)               0         \n",
            "_________________________________________________________________\n",
            "dense0 (Dense)               (None, 5)                 965       \n",
            "=================================================================\n",
            "Total params: 162,533\n",
            "Trainable params: 162,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "input = tf.keras.layers.Input(shape=(20, 333, 1),name='input1')\n",
        "x = tf.keras.layers.Conv2D(128, (2,6), activation='relu', strides=(2,2), name='conv2')(input)\n",
        "x = tf.keras.layers.Conv2D(64, (2,6), activation='relu', strides=(2,2), name='conv3')(x)\n",
        "x = tf.keras.layers.Conv2D(48, (2,6), activation='relu', strides=(1,2), name='conv4')(x)\n",
        "x = tf.keras.layers.Conv2D(32, (2,6), activation='relu', strides=(1,2),name='conv5')(x)\n",
        "x = tf.keras.layers.Conv2D(16, (2,6), activation='relu', strides=(1,2),name='conv6')(x)\n",
        "x = tf.keras.layers.Flatten(name='flatten1')(x)\n",
        "output = tf.keras.layers.Dense(5,name=\"dense0\")(x)\n",
        "\n",
        "\n",
        "bce=tf.keras.losses.BinaryCrossentropy()\n",
        "encoder = Model(input, output, name=\"encoder\")\n",
        "optimizer = Adam()\n",
        "encoder.compile(optimizer=optimizer, loss=bce)\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j8ZFzmGCRs0"
      },
      "outputs": [],
      "source": [
        "\n",
        "encoder.layers[0].set_weights(autoencoder.layers[0].get_weights())\n",
        "encoder.layers[1].set_weights(autoencoder.layers[1].get_weights())\n",
        "encoder.layers[2].set_weights(autoencoder.layers[2].get_weights())\n",
        "encoder.layers[3].set_weights(autoencoder.layers[3].get_weights())\n",
        "encoder.layers[4].set_weights(autoencoder.layers[4].get_weights())\n",
        "encoder.layers[5].set_weights(autoencoder.layers[5].get_weights())\n",
        "encoder.layers[6].set_weights(autoencoder.layers[6].get_weights())\n",
        "encoder.layers[7].set_weights(autoencoder.layers[7].get_weights())\n",
        "\n",
        "encoder.save('encoder_perceptual.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adNGhnyLCtJb",
        "outputId": "4c4dd2f0-038d-47cd-96fd-f92b106bd2f2",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2700, 20, 333)\n",
            "(2700, 20, 333)\n",
            "85/85 - 1s\n",
            "85/85 - 1s\n",
            "(2700,) (2700,)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "filN=np.load('dataN.npz')\n",
        "filA=np.load('MS_sgn_2_mod.npz')\n",
        "\n",
        "dataA=filA['data_noise']\n",
        "dataN=filN['data']\n",
        "\n",
        "\n",
        "dataA=dataA[0:2700]\n",
        "dataN=dataN[0:2700]\n",
        "\n",
        "dataA=make_binary(dataA)\n",
        "dataN=make_binary(dataN)\n",
        "\n",
        "dataA=np.reshape(dataA,(2700,20,333,1))\n",
        "dataN=np.reshape(dataN,(2700,20,333,1))\n",
        "\n",
        "\n",
        "rN=encoder.predict(dataN,verbose=2)\n",
        "rA=encoder.predict(dataA,verbose=2)\n",
        "\n",
        "\n",
        "RN=[]\n",
        "RA=[]\n",
        "\n",
        "for i in range(len(rN)):\n",
        "    RN.append(np.sum(rN[i]))\n",
        "    RA.append(np.sum(rA[i]))\n",
        "    \n",
        "RN=np.asarray(RN)\n",
        "RA=np.asarray(RA)\n",
        "print(RA.shape,RN.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSk6oe69ia-K",
        "outputId": "8d1e0852-f266-4434-ca5d-cae6906cd9f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig=plt.figure()\n",
        "fig,ax=plt.subplots()\n",
        "plt.hist(RA,bins=80, alpha=0.5, color='red',density=True, label='anomali',histtype='step')\n",
        "plt.hist(RN,bins=80, alpha=0.5,color='blue', density=True, label='normali',histtype='step')\n",
        "#ax.set_xlabel('Binary crossentropy')\n",
        "ax.set_ylabel('Frequency of occurrence')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtBZN407CRs1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxhxsqhKCRs1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}